{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "input: transactions_370k\n",
    "\n",
    "Find correspondence between plan-days and actual-paid. If more than one values of 'actual-paid' are found for a value of 'plan-days', choose the one that has the largest number of records. Only records with transaction_date < 20160101, plan_days > 0 and actual_paid > 0 are considered.\n",
    "\n",
    "output: 'master' local: /home/master/iii_projects_data/kkbox_churn/data01/004.plan-days_vs_actual-paid.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.120.27.99:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff95ff1f320>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'file:///home/cloudera/Desktop/KKBox_churn_predict/data01/transactions_370k.csv'\n",
    "df0 = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- payment_method_id: integer (nullable = true)\n",
      " |-- payment_plan_days: integer (nullable = true)\n",
      " |-- plan_list_price: integer (nullable = true)\n",
      " |-- actual_amount_paid: integer (nullable = true)\n",
      " |-- is_auto_renew: integer (nullable = true)\n",
      " |-- transaction_date: integer (nullable = true)\n",
      " |-- membership_expire_date: integer (nullable = true)\n",
      " |-- is_cancel: integer (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df0.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df0.selectExpr('msno', 'transaction_date as trans_date', \n",
    "                     'payment_plan_days AS plan_days', 'actual_amount_paid AS actual_paid',\n",
    "                     'is_cancel') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+-----------+---------+\n",
      "|                msno|trans_date|plan_days|actual_paid|is_cancel|\n",
      "+--------------------+----------+---------+-----------+---------+\n",
      "|+/namlXq+u3izRjHC...|  20150831|        0|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20170228|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20161031|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160531|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20151231|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20170131|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20150930|        0|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160430|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20151031|        0|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160831|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160331|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20151130|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160731|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160131|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20161130|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20150731|        0|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20161231|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20150630|        0|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160930|       30|        149|        0|\n",
      "|+/namlXq+u3izRjHC...|  20160229|       30|        149|        0|\n",
      "+--------------------+----------+---------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|actual_paid|plan_days|  count|\n",
      "+-----------+---------+-------+\n",
      "|         10|        2|      1|\n",
      "|         15|        3|      1|\n",
      "|         35|        7|    770|\n",
      "|         50|       10|     29|\n",
      "|         99|       30|  24797|\n",
      "|        100|       30|   2147|\n",
      "|        105|       21|     48|\n",
      "|        119|       30|  67883|\n",
      "|        127|       30|     17|\n",
      "|        129|       30|  97136|\n",
      "|        131|       30|     22|\n",
      "|        134|       30|    394|\n",
      "|        149|       35|     54|\n",
      "|        149|       30|1477207|\n",
      "|        149|       31| 395702|\n",
      "|        150|       30|  63400|\n",
      "|        210|       30|     15|\n",
      "|        265|       60|      1|\n",
      "|        300|       60|    751|\n",
      "|        350|       70|     73|\n",
      "|        400|       80|     45|\n",
      "|        447|       90|    281|\n",
      "|        450|       90|    172|\n",
      "|        480|      100|   1256|\n",
      "|        500|       30|      1|\n",
      "|        500|      100|     95|\n",
      "|        536|      180|   2439|\n",
      "|        596|      120|      1|\n",
      "|        760|      180|      1|\n",
      "|        799|      180|    595|\n",
      "|        894|      180|     79|\n",
      "|        894|      195|  10100|\n",
      "|        930|      200|    240|\n",
      "|       1000|      200|     64|\n",
      "|       1150|      230|     15|\n",
      "|       1200|      360|    403|\n",
      "|       1599|      395|    658|\n",
      "|       1599|      400|    256|\n",
      "|       1788|      365|      7|\n",
      "|       1788|      410|   8412|\n",
      "|       1788|      450|    131|\n",
      "|       2000|      400|     10|\n",
      "+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df2 = df1.where('is_cancel = 0').where(col('trans_date') < '20160101').where('plan_days > 0').where('actual_paid > 0') \\\n",
    "         .groupBy('actual_paid', 'plan_days').count().sort('actual_paid')\n",
    "\n",
    "df2.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, (1, 2)),\n",
       " (15, (1, 3)),\n",
       " (35, (770, 7)),\n",
       " (50, (29, 10)),\n",
       " (99, (24797, 30)),\n",
       " (100, (2147, 30)),\n",
       " (105, (48, 21)),\n",
       " (119, (67883, 30)),\n",
       " (127, (17, 30)),\n",
       " (129, (97136, 30)),\n",
       " (131, (22, 30)),\n",
       " (134, (394, 30)),\n",
       " (149, (1477207, 30)),\n",
       " (149, (54, 35)),\n",
       " (149, (395702, 31)),\n",
       " (150, (63400, 30)),\n",
       " (210, (15, 30)),\n",
       " (265, (1, 60)),\n",
       " (300, (751, 60)),\n",
       " (350, (73, 70))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = df2.rdd\n",
    "rdd3 = rdd2.map(lambda row: (row[0], (row['count'], row['plan_days'])))\n",
    "\n",
    "rdd3.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.combineByKey(lambda p: p, \n",
    "                         lambda p1, p2: p1 if p1[0]>p2[0] else p2,\n",
    "                         lambda p1, p2: p1 if p1[0]>p2[0] else p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 2),\n",
       " (15, 3),\n",
       " (35, 7),\n",
       " (50, 10),\n",
       " (99, 30),\n",
       " (100, 30),\n",
       " (105, 21),\n",
       " (119, 30),\n",
       " (127, 30),\n",
       " (129, 30),\n",
       " (131, 30),\n",
       " (134, 30),\n",
       " (149, 30),\n",
       " (150, 30),\n",
       " (210, 30)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5 = rdd4.map(lambda p: (p[0], p[1][1])).sortByKey()\n",
    "\n",
    "rdd5.take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = rdd5.toDF()\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "| 10|  2|\n",
      "| 15|  3|\n",
      "| 35|  7|\n",
      "| 50| 10|\n",
      "| 99| 30|\n",
      "|100| 30|\n",
      "|105| 21|\n",
      "|119| 30|\n",
      "|127| 30|\n",
      "|129| 30|\n",
      "|131| 30|\n",
      "|134| 30|\n",
      "|149| 30|\n",
      "|150| 30|\n",
      "|210| 30|\n",
      "|265| 60|\n",
      "|300| 60|\n",
      "|350| 70|\n",
      "|400| 80|\n",
      "|447| 90|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.selectExpr(\"_1 AS actual_paid\", \"_2 AS plan_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.coalesce(1).write.format('csv').option('header','true').save('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
